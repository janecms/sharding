# Redis
## 持久化
### RDB
```
save 60 1000
```
	每隔60s，如果有超过1000个key发生了变更，那么就生成一个新的dump.rdb文件;
	save可以设置多个，就是多个snapshotting检查点，每到一个检查点，就会去check一下

- RDB持久化机制的工作流程

	- （1）redis根据配置自己尝试去生成rdb快照文件

	- （2）fork一个子进程出来

	- （3）子进程尝试将数据dump到临时的rdb快照文件中

	- （4）完成rdb快照文件的生成之后，就替换之前的旧的快照文件
	
dump.rdb，每次生成一个新的快照，都会覆盖之前的老快照

### AOF

```
appendonly yes
```
AOF持久化，默认是关闭的，默认是打开RDB持久化.redis重启时，优先通过AOF进行数据恢复的.
redis每次接收到一条写命令，就会写入日志文件中，当然是先写入os cache的，然后每隔一定时间再fsync一下

- 配置AOF的fsync策略
	-	always: 每次写入一条数据，立即将这个数据对应的写日志fsync到磁盘上去，性能非常非常差，吞吐量很低; 	

	-	everysec: 每秒将os cache中的数据fsync到磁盘，这个最常用的，生产环境一般都这么配置，性能很高，QPS还是可以上万的

	-	no: 仅仅redis负责将数据写入os cache就撒手不管了，然后后面os自己会时不时有自己的策略将数据刷入磁盘，不可控了

- AOF rewrite
```
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
```

- 过程

	- （1）redis fork一个子进程
	- （2）子进程基于当前内存中的数据，构建日志，开始往一个新的临时的AOF文件中写入日志
	- （3）redis主进程，接收到client新的写操作之后，在内存中写入日志，同时新的日志也继续写入旧的AOF文件
	- （4）子进程写完新的日志文件之后，redis主进程将内存中的新日志再次追加到新的AOF文件中
	- （5）用新的日志文件替换掉旧的日志文件

用redis-check-aof --fix命令来修复破损的AOF文件

- 5、AOF和RDB同时工作

	-	（1）如果RDB在执行snapshotting操作，那么redis不会执行AOF rewrite; 如果redis再执行AOF rewrite，那么就不会执行RDB snapshotting

	-	（2）如果RDB在执行snapshotting，此时用户执行BGREWRITEAOF命令，那么等RDB快照生成之后，才会去执行AOF rewrite

	-	（3）同时有RDB snapshot文件和AOF日志文件，那么redis重启的时候，会优先使用AOF进行数据恢复，因为其中的日志更完整
		
***
## redis replication

### redis replication的核心机制

- （1）redis采用异步方式复制数据到slave节点，不过redis 2.8开始，slave node会周期性地确认自己每次复制的数据量
- （2）一个master node是可以配置多个slave node的
- （3）slave node也可以连接其他的slave node
- （4）slave node做复制的时候，是不会block master node的正常工作的
- （5）slave node在做复制的时候，也不会block对自己的查询操作，它会用旧的数据集来提供服务; 
		但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了
- （6）slave node主要用来进行横向扩容，做读写分离，扩容的slave node可以提高读的吞吐量

（1）master和slave都会维护一个offset

master会在自身不断累加offset，slave也会在自身不断累加offset
slave每秒都会上报自己的offset给master，同时master也会保存每个slave的offset

（2）backlog

master node有一个backlog，默认是1MB大小
master node给slave node复制数据时，也会将数据在backlog中同步写一份
backlog主要是用来做全量复制中断候的增量复制的

（3）master run id

info server，可以看到master run id
如果根据host+ip定位master node，是不靠谱的，如果master node重启或者数据出现了变化，那么slave node应该根据不同的run id区分，run id不同就做全量复制
如果需要不更改run id重启redis，可以使用redis-cli debug reload命令

（4）psync

从节点使用psync从master node进行复制，psync runid offset
master node会根据自身的情况返回响应信息，可能是FULLRESYNC runid offset触发全量复制，可能是CONTINUE触发增量复制

	

### 主从架构的核心原理

-	当启动一个slave node的时候，它会发送一个PSYNC命令给master node

-	如果这是slave node重新连接master node，那么master node仅仅会复制给slave部分缺少的数据; 
否则如果是slave node第一次连接master node，那么会触发一次full resynchronization

-	开始full resynchronization的时候，master会启动一个后台线程，开始生成一份RDB快照文件，
同时还会将从客户端收到的所有写命令缓存在内存中。
RDB文件生成完毕之后，master会将这个RDB发送给slave，slave会先写入本地磁盘，
然后再从本地磁盘加载到内存中。然后master会将内存中缓存的写命令发送给slave，
slave也会同步这些数据。

-	slave node如果跟master node有网络故障，断开了连接，会自动重连。master如果发现有多个slave node都来重新连接，
仅仅会启动一个rdb save操作，用一份数据服务所有slave node。

### 主从复制的断点续传

master node会在内存中常见一个backlog，master和slave都会保存一个replica offset还有一个master id，
offset就是保存在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的replica offset开始继续复制

但是如果没有找到对应的offset，那么就会执行一次resynchronization

### 无磁盘化复制
```
repl-diskless-sync
repl-diskless-sync-delay，等待一定时长再开始复制，因为要等更多slave重新连接过来
```
master在内存中直接创建rdb，然后发送给slave，不会在自己本地落地磁盘了

### 过期key处理

slave不会过期key，只会等待master过期key。
如果master过期了一个key，或者通过LRU淘汰了一个key，那么会模拟一条del命令发送给slave。


### 完整流程

- （1）slave node启动，仅仅保存master node的信息，包括master node的host和ip，但是复制流程没开始

master host和ip是从哪儿来的，redis.conf里面的slaveof配置的

- （2）slave node内部有个定时任务，每秒检查是否有新的master node要连接和复制，
		如果发现，就跟master node建立socket网络连接
		
- （3）slave node发送ping命令给master node

- （4）口令认证，如果master设置了requirepass，那么salve node必须发送masterauth的口令过去进行认证

- （5）master node第一次执行全量复制，将所有数据发给slave node

- （6）master node后续持续将写命令，异步复制给slave node

### 3、全量复制

- （1）master执行bgsave，在本地生成一份rdb快照文件
- （2）master node将rdb快照文件发送给salve node，如果rdb复制时间超过60秒（repl-timeout），
那么slave node就会认为复制失败，可以适当调节大这个参数
- （3）对于千兆网卡的机器，一般每秒传输100MB，6G文件，很可能超过60s
- （4）master node在生成rdb时，会将所有新的写命令缓存在内存中，在salve node保存了rdb之后，再将新的写命令复制给salve node
- （5）client-output-buffer-limit slave 256MB 64MB 60，
如果在复制期间，内存缓冲区持续消耗超过64MB，或者一次性超过256MB，那么停止复制，复制失败
- （6）slave node接收到rdb之后，清空自己的旧数据，然后重新加载rdb到自己的内存中，
同时基于旧的数据版本对外提供服务
- （7）如果slave node开启了AOF，那么会立即执行BGREWRITEAOF，重写AOF

### heartbeat

主从节点互相都会发送heartbeat信息

master默认每隔10秒发送一次heartbeat，salve node每隔1秒发送一个heartbeat

### 异步复制

master每次接收到写命令之后，先在内部写入数据，然后异步发送给slave node
